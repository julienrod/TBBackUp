{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour train\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'include.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e1371cdcb698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_data_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'include.data'"
     ]
    }
   ],
   "source": [
    "from include.data import get_data_set #Marche pas\n",
    "from include.model import model, lr   #Pareil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = get_data_set(\"train\")\n",
    "test_x, test_y = get_data_set(\"test\")\n",
    "tf.set_random_seed(21)\n",
    "x, y, output, y_pred_cls, global_step, learning_rate = model()\n",
    "global_accuracy = 0\n",
    "epoch_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "_BATCH_SIZE = 128\n",
    "_EPOCH = 60\n",
    "_SAVE_PATH = \"./it/does/not/work/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-c3a737aa7893>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-c3a737aa7893>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    beta=0.9\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Loss and optimizer\n",
    "loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=output, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate\n",
    "                                  beta1=0.9 #Doesn't work\n",
    "                                  beta2=0.999\n",
    "                                  epsilon=1e-08).minimize(\n",
    "                                      loss, \n",
    "                                      global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction and accuracy calculation\n",
    "correct_prediction = tf.equal(y_pred_cls, tf.argmax(y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predicition, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saver\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "train_writer = tf.summary.FileWriter(_SAVE_PATH,sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Trying to restore last checkpoint ...\")\n",
    "    last_chk_path = tf.train.latest_checkpoint(\n",
    "        checkpoint_dir=_SAVE_PATH)\n",
    "    saver.restore(sess, save_path=last_chk_path)\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except ValueError:\n",
    "    print(\"Failed to restore checkpoint. Initializing\", \n",
    "          \"variable instead.\")\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-60b9e435522b>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-60b9e435522b>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    globel epoch_start\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    global epoch_start\n",
    "    epoch_start = time()\n",
    "    batch_size = int(math.ceil(len(train_x) / _BATCH_SIZE))\n",
    "    i_global = 0\n",
    "    \n",
    "    for s in range(batch_size):\n",
    "        batch_xs = train_x[s*_BATCH_SIZE:(s+1)*_BATCH_SIZE]\n",
    "        batch_ys = train_y[s*_BATCH_SIZE:(s+1)*_BATCH_SIZE]\n",
    "        \n",
    "        start_time = time()\n",
    "        i_global, _, batch_loss, batch_acc = sess.run(\n",
    "            [global_step, optimizer, loss, accuracy],\n",
    "            feed_dict={x: batch_xs, y: batch_ys, \n",
    "                       learning_rate: lr(epoch)})\n",
    "        duration = time() - start_time\n",
    "        \n",
    "        if s % 10 == 0:\n",
    "            percentage = int(round((s/batch_size)*100))\n",
    "            bar_len = 29\n",
    "            filled_len = int((bar_len*int(percentage))/100)\n",
    "            bar = '=' * filled_len + '>' + \"-\" * (\n",
    "                bar_len - filled_len)\n",
    "            msg = \"Global step: {:>5} - [{}] {:>3}% -\",\n",
    "                  \"acc: {:.4f} - loss: {:.4f} - {:.1f}\",\n",
    "                  \"sample/sec\"\n",
    "            print(msg.format(i_global, bar, percentage,\n",
    "                            batch_acc, batch_loss,\n",
    "                            _BATCH_SIZE / duration))\n",
    "    test_and_save(i_global, epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_and_save(_global_step, epoch):\n",
    "    global global_accuracy\n",
    "    global epoch_start\n",
    "    \n",
    "    i = 0\n",
    "    predicted_class = np.zeros(shape=len(test_x),\n",
    "                               dtype=np.int)\n",
    "    while i < len(test_x):\n",
    "        j = min(i + _BATCH_SIZE, len(test_x))\n",
    "        batch_xs = test_x[i:j, :]\n",
    "        batch_ys = test_y[i:j, :]\n",
    "        predicted_class[i:j] = sess.run(y_pred_cls,\n",
    "                                       feed_dict={\n",
    "                                           x: batch_xs,\n",
    "                                           y: batch_ys,\n",
    "                                           learning_rate:\n",
    "                                               lr(epoch)\n",
    "                                       })\n",
    "        i = j\n",
    "        correct = (np.argmax(test_y, axis=1) == \n",
    "                   predicted_class)\n",
    "        acc = correct.mean()*100\n",
    "        correct_numbers = correct.sum()\n",
    "        hours, rem = divmod(time() - epoch_start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        mes = \"Epoch  {} - accuracy: {:.2f}% ({}/{}) -\",\n",
    "              \"time: {:0>2}:{:0>2}:{:05.2f}\"\n",
    "    print(mes.format((epoch+1), acc, correct_numbers,\n",
    "                    len(test_x), int(hours), seconds))\n",
    "    \n",
    "    if global_accuracy != 0 and global_accuracy < acc:\n",
    "        summary = tf.Summary(value[\n",
    "            tf.Summary.Value(tag=\"Accuracy/test\",\n",
    "                            simple_value=acc),]) #?\n",
    "        train_writer.add_summary(summary, _global_step)\n",
    "        saver.save(sess, save_path=_SAVE_PATH,\n",
    "                  global_step=_global_step)\n",
    "        mes = \"This epoch receive better accuracy: {:.2f}.\",\n",
    "              \"Saving session...\"\n",
    "    elif global_accuracy == 0:\n",
    "        global_accuracy = acc\n",
    "        \n",
    "    print(\"#############################################\"+\n",
    "          \"#############################################\"+\n",
    "          \"#################\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_start = time()\n",
    "    \n",
    "    for i in range(_EPOCH):\n",
    "        print(\"Epoch: {}/{}\".format((i+1), _EPOCH))\n",
    "        train(i)\n",
    "    \n",
    "    hours, rem = divmod(time() - train_start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    mes = \"Best accuracy pre session: {:.2f}, time:\",\n",
    "          \"{:0>2}:{:0>2}:{05.2f}\"\n",
    "    print(mes.format(global_accuracy, int(hours), \n",
    "                     int(minutes), seconds))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour test\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from include.data import get_data_set\n",
    "from include.model import model\n",
    "\n",
    "test_x, test_y = get_data_set(\"test\")\n",
    "x, y, output, y_pred_cls, global_step, learning_rate=model()\n",
    "\n",
    "_BATCH_SIZE = 128\n",
    "_CLASS_SIZE = 10\n",
    "_SAVE_PATH = \"./does/not/work/anyways\"\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Trying to restore last checkpoint ...\")\n",
    "    last_chk_path = tf.train.latest_checkpoint(\n",
    "                          checkpoint_dir=_SAVE_PATH)\n",
    "    saver.restore(sess, save_path=last_chk_path)\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except ValueError:\n",
    "    print(\"Failed to restore checkpoint. Initializing\",\n",
    "         \"variables insead.\")\n",
    "    sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    i = 0\n",
    "    predicted_class = np.zeros(shape= len(test_x),\n",
    "                               dtype=np.int)\n",
    "    while i < len(test_x):\n",
    "        j = min(i + _BATCH_SIZE, len(test_x))\n",
    "        batch_xs = test_x[i:j, :]\n",
    "        batch_ys = test_y[i:j, :]\n",
    "        predicted_class[i:j] = sess.run(y_pred_cls,\n",
    "                                       feed_dict={\n",
    "                                           x: batch_xs,\n",
    "                                           y: batch_ys      \n",
    "                                       })\n",
    "        i = j\n",
    "    correct = (np.argmax(test_y, axis=1) == predicted_class)\n",
    "    acc = correct.mean() * 100\n",
    "    correct_numbers = correct.sum()\n",
    "    print()\n",
    "    print(\"Accuracy on Test-Set: {0:.2f}% ({1} / {2})\".\n",
    "         format(acc, correct_numbers, len(test_x)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "sess.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
