{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_OF_DIRECTORIES = [\"output/sentinel1/ambiguous/coffee\", \"output/sentinel1/ambiguous/other\",\n",
    "                       \"output/sentinel1/ambiguous/pepper\", \"output/sentinel1/cassava\", \"output/sentinel1/coffee\",\n",
    "                       \"output/sentinel1/deciduous_forest\", \"output/sentinel1/intercrop\", \"output/sentinel1/native_no_tree\",\n",
    "                       \"output/sentinel1/nativevege\", \"output/sentinel1/other_tree\", \"output/sentinel1/pepper\",\n",
    "                       \"output/sentinel1/pine_trees\", \"output/sentinel1/rice\", \"output/sentinel1/rubber\",\n",
    "                       \"output/sentinel1/seasonal\", \"output/sentinel1/stick_pepper\", \"output/sentinel1/tea\",\n",
    "                       \"output/sentinel1/urban\", \"output/sentinel1/water\"]\n",
    "COUNTAIN_START = \"coffee\"\n",
    "PIXEL_LENGTH = 30\n",
    "BAND_WIDTH = 12\n",
    "NB_SPLIT = 5\n",
    "EPOCH = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Première étape : charger les données\n",
    "\n",
    "Importer le nom des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "import random\n",
    "import rasterio\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images_names(directories): \n",
    "    images_name = []\n",
    "    for directory in directories:\n",
    "        counter = 0\n",
    "        for filename in os.listdir(directory): \n",
    "            if os.path.isfile(directory + \"/\" + filename):\n",
    "                images_name.append(directory + \"/\" + filename)\n",
    "                counter += 1\n",
    "            elif os.path.isdir(directory + \"/\" + filename):\n",
    "                images_name += get_all_images_names([directory + \"/\" + filename])\n",
    "        print(directory, counter, \"images.\")\n",
    "    return images_name\n",
    "images_name = get_all_images_names(LIST_OF_DIRECTORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer les images et leur résultat voulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(image):\n",
    "    \"\"\"Reformate les données rasterio pour être utilisée par Tensorflow\"\"\"\n",
    "    reshaped_image = []\n",
    "    for i in range(len(image[0])):\n",
    "        reshaped_row = []\n",
    "        for j in range(len(image[0][0])):\n",
    "            reshaped_cell = []\n",
    "            #Fall\n",
    "            reshaped_cell.append(image[0][i][j] / 65535)\n",
    "            reshaped_cell.append(image[1][i][j] / 65535)\n",
    "            reshaped_cell.append(image[2][i][j] / 65535)\n",
    "            #Winter\n",
    "            reshaped_cell.append(image[3][i][j] / 65535)\n",
    "            reshaped_cell.append(image[4][i][j] / 65535)\n",
    "            reshaped_cell.append(image[5][i][j] / 65535)\n",
    "            #Spring\n",
    "            reshaped_cell.append(image[6][i][j] / 65535)\n",
    "            reshaped_cell.append(image[7][i][j] / 65535)\n",
    "            reshaped_cell.append(image[8][i][j] / 65535)\n",
    "            #Summer\n",
    "            reshaped_cell.append(image[9][i][j] / 65535)\n",
    "            reshaped_cell.append(image[10][i][j] / 65535)\n",
    "            reshaped_cell.append(image[11][i][j] / 65535)\n",
    "            #Si les images utilisées ne possède pas toutes les 12 bandes (si la séléction des bandes a déjà été faite)\n",
    "            #utiliser plutôt le code suivant\n",
    "            #for k in range(BAND_WIDTH):\n",
    "            #     reshaped_cell.append(image[k][i][j] / 65535)\n",
    "            \n",
    "            reshaped_row.append(reshaped_cell)\n",
    "        reshaped_image.append(reshaped_row)\n",
    "    return reshaped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image_name in images_name:\n",
    "    if COUNTAIN_START in image_name:\n",
    "        images.append((np.array(rasterio.open(image_name).read()), 1))\n",
    "    else:\n",
    "        images.append((np.array(rasterio.open(image_name).read()), 0))\n",
    "print(\"Longueur initiale : \", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_rotations(images):\n",
    "    result = []\n",
    "    for image in images:\n",
    "        result.append(image)\n",
    "        for i in range (1, 4):\n",
    "            rotated_image = []\n",
    "            #Si les images utilisées ne possède pas toutes les 12 bandes (si la séléction des bandes a déjà été faite)\n",
    "            #utiliser BAND_WIDTH au lieu de 12.\n",
    "            for j in range(12): \n",
    "                rotated_image.append(np.rot90(image[0][j], i))\n",
    "            result.append((rotated_image, image[1]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = add_all_rotations(images)\n",
    "random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_x = []\n",
    "images_y = []\n",
    "for image in images:\n",
    "    images_x.append(reshape(image[0]))\n",
    "    images_y.append(image[1])\n",
    "images_x = np.array(images_x).reshape(len(images_x), PIXEL_LENGTH, PIXEL_LENGTH, BAND_WIDTH)\n",
    "images_y = np.array(images_y)\n",
    "print(\"Longueur du set d'entrainement : \", len(images_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deuxième étape : créer notre cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics as me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=NB_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = None\n",
    "pas_cafe = np.count_nonzero(images_y < 1)\n",
    "cafe = len(images_y) - pas_cafe\n",
    "print(pas_cafe, len(images_y))\n",
    "print(pas_cafe / len(images_y))\n",
    "if pas_cafe < cafe:\n",
    "    class_weight = {0: cafe / pas_cafe,1: 1.} \n",
    "else:\n",
    "    class_weight = {0: 1., 1: pas_cafe / cafe} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troisième étape : entrainer et tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fscore_recall_precision(truth, prediction):\n",
    "    true_positive = 0\n",
    "    false_negative = 0\n",
    "    false_positive = 0\n",
    "    for i in range(len(truth)):\n",
    "        if truth[i] == 1 and prediction[i] == 1:\n",
    "            true_positive += 1\n",
    "        elif truth[i] == 0 and prediction[i] == 1:\n",
    "            false_positive += 1\n",
    "        elif truth[i] == 1 and prediction[i] == 0:\n",
    "            false_negative += 1\n",
    "    precision = true_positive/(true_positive + false_positive) if (true_positive + false_positive) > 0 else None\n",
    "    recall = true_positive/(true_positive + false_negative) if (true_positive + false_negative) > 0 else None\n",
    "    fscore = 2 * recall * precision / (recall + precision) if recall != None and precision != None else None\n",
    "    return fscore, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "avg_scores = []\n",
    "avg_recall = []\n",
    "avg_precision = []\n",
    "avg_fscore = []\n",
    "i = 0\n",
    "print(class_weight)\n",
    "for train, test in kfold.split(images_x, images_y):\n",
    "    print(np.count_nonzero(images_y[train] < 1), len(images_y[train]))\n",
    "    print(np.count_nonzero(images_y[test] < 1), len(images_y[test]))\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3,3), activation='relu',  input_shape=(PIXEL_LENGTH,PIXEL_LENGTH,BAND_WIDTH)))\n",
    "    model.add(MaxPooling2D(pool_size = (2 ,2)))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2 ,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    history = model.fit(images_x[train], images_y[train], epochs=EPOCH, batch_size=32, \n",
    "                        validation_data=(images_x[test], images_y[test]), class_weight=class_weight)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(images_x[test], images_y[test], verbose=0)\n",
    "    print(\"iteration\", i)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    avg_scores.append(scores[1] * 100)\n",
    "    #model.save(\"model\"+str(i)+\"s1.h5\")\n",
    "    i += 1\n",
    "    \n",
    "    pl.plot(history.history['loss'], label='Training')\n",
    "    pl.plot(history.history['val_loss'], label='Testing')\n",
    "    pl.ylim(0, 2) \n",
    "    pl.legend()\n",
    "    pl.grid()\n",
    "    print('Test score:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    pl.show()\n",
    "    \n",
    "    pred = model.predict_classes(images_x[test])\n",
    "    f, r, p = get_fscore_recall_precision(images_y[test], pred)\n",
    "    print('Test recall', r)\n",
    "    print('Test precision', p)\n",
    "    print('Test f-score', f)\n",
    "    if f != None and p != 0:\n",
    "        avg_recall.append(r * 100)\n",
    "        avg_precision.append(p * 100)\n",
    "        avg_fscore.append(f * 100)\n",
    "    print(me.confusion_matrix(images_y[test], pred))\n",
    "    \n",
    "print(\"Accuracy %.2f%% (+/- %.2f%%)\" % (np.mean(avg_scores), np.std(avg_scores)))\n",
    "print(\"Recall %.2f%% (+/- %.2f%%)\" % (np.mean(avg_recall), np.std(avg_recall)))\n",
    "print(\"Precision %.2f%% (+/- %.2f%%)\" % (np.mean(avg_precision), np.std(avg_precision)))\n",
    "print(\"F-Score %.2f%% (+/- %.2f%%)\" % (np.mean(avg_fscore), np.std(avg_fscore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
