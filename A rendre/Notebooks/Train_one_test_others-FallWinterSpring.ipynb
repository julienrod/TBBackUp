{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_OF_DIRECTORIES = [\"output/basfws/ambiguous/coffee\", \"output/basfws/ambiguous/other\", \"output/basfws/coffee\",\n",
    "                       \"output/basfws/intercrop\", \"output/basfws/native_no_tree\", \"output/basfws/nativevege\",\n",
    "                       \"output/basfws/other_tree\", \"output/basfws/pepper\", \"output/basfws/pine_trees\",\n",
    "                       \"output/basfws/rice\", \"output/basfws/rubber\", \"output/basfws/seasonal\", \"output/basfws/tea\",\n",
    "                       \"output/basfws/urban\", \"output/basfws/water\", \"output/droitefws/ambiguous\",\n",
    "                       \"output/droitefws/coffee\", \"output/droitefws/native_no_tree\", \"output/droitefws/nativevege\",\n",
    "                       \"output/droitefws/other_tree\", \"output/droitefws/pepper\", \"output/droitefws/pine_trees\",\n",
    "                       \"output/droitefws/rice\", \"output/droitefws/rubber\", \"output/droitefws/seasonal\", \n",
    "                       \"output/droitefws/tea\", \"output/droitefws/urban\", \"output/droitefws/water\", \n",
    "                       \"output/gauchefws/ambiguous/coffee\", \"output/gauchefws/ambiguous/pepper\",\n",
    "                       \"output/gauchefws/coffee\", \"output/gauchefws/intercrop\", \"output/gauchefws/native_no_tree\",\n",
    "                       \"output/gauchefws/nativevege\", \"output/gauchefws/other_tree\", \"output/gauchefws/pepper\",\n",
    "                       \"output/gauchefws/rice\", \"output/gauchefws/rubber\", \"output/gauchefws/seasonal\",\n",
    "                       \"output/gauchefws/stick_pepper\", \"output/gauchefws/urban\", \"output/gauchefws/water\",\n",
    "                       \"output/hautfws/ambiguous/coffee\", \"output/hautfws/ambiguous/other\", \"output/hautfws/cassava\",\n",
    "                       \"output/hautfws/coffee\", \"output/hautfws/deciduous_forest\", \"output/hautfws/intercrop\",\n",
    "                       \"output/hautfws/native_no_tree\", \"output/hautfws/nativevege\", \"output/hautfws/other_tree\",\n",
    "                       \"output/hautfws/pepper\", \"output/hautfws/pine_trees\", \"output/hautfws/rice\", \n",
    "                       \"output/hautfws/rubber\", \"output/hautfws/seasonal\", \"output/hautfws/tea\", \"output/hautfws/urban\",\n",
    "                       \"output/hautfws/water\", \"output/milieufws/cassava\", \"output/milieufws/coffee\",\n",
    "                       \"output/milieufws/deciduous_forest\", \"output/milieufws/intercrop\", \n",
    "                       \"output/milieufws/native_no_tree\", \"output/milieufws/nativevege\", \"output/milieufws/other_tree\",\n",
    "                       \"output/milieufws/pepper\", \"output/milieufws/rice\", \"output/milieufws/rubber\",\n",
    "                       \"output/milieufws/seasonal\", \"output/milieufws/urban\", \"output/milieufws/water\"]\n",
    "COUNTAIN_COFFEE = \"coffee\"\n",
    "ZONES = [\"basfws\", \"droitefws\", \"gauchefws\", \"hautfws\", \"milieufws\"]\n",
    "PIXEL_LENGTH = 15\n",
    "BAND_WIDTH = 9\n",
    "NB_SPLIT = 5\n",
    "EPOCH = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Première étape : charger les données\n",
    "\n",
    "Importer le nom des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as pl\n",
    "import random\n",
    "import rasterio\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images_names(directories): \n",
    "    images_name = []\n",
    "    for directory in directories:\n",
    "        counter = 0\n",
    "        for filename in os.listdir(directory): \n",
    "            if os.path.isfile(directory + \"/\" + filename):\n",
    "                images_name.append(directory + \"/\" + filename)\n",
    "                counter += 1\n",
    "            elif os.path.isdir(directory + \"/\" + filename):\n",
    "                images_name += get_all_images_names([directory + \"/\" + filename])\n",
    "        print(directory, counter, \"images.\")\n",
    "    return images_name\n",
    "images_name = get_all_images_names(LIST_OF_DIRECTORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importer les images et leur résultat voulu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(image):\n",
    "    \"\"\"Reformate les données rasterio pour être utilisée par Tensorflow\"\"\"\n",
    "    reshaped_image = []\n",
    "    for i in range(len(image[0])):\n",
    "        reshaped_row = []\n",
    "        for j in range(len(image[0][0])):\n",
    "            reshaped_cell = []\n",
    "            \n",
    "            reshaped_cell.append(image[0][i][j] / 65535)\n",
    "            reshaped_cell.append(image[1][i][j] / 65535)\n",
    "            #reshaped_cell.append(image[2][i][j] / 65535)\n",
    "            reshaped_cell.append(image[3][i][j] / 65535)\n",
    "            \n",
    "            reshaped_cell.append(image[4][i][j] / 65535)\n",
    "            #reshaped_cell.append(image[5][i][j] / 65535)\n",
    "            reshaped_cell.append(image[6][i][j] / 65535)\n",
    "            reshaped_cell.append(image[7][i][j] / 65535)\n",
    "            \n",
    "            reshaped_cell.append(image[8][i][j] / 65535)\n",
    "            reshaped_cell.append(image[9][i][j] / 65535)\n",
    "            #reshaped_cell.append(image[10][i][j] / 65535)\n",
    "            reshaped_cell.append(image[11][i][j] / 65535)\n",
    "            \n",
    "            reshaped_row.append(reshaped_cell)\n",
    "        reshaped_image.append(reshaped_row)\n",
    "    return reshaped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for image_name in images_name:\n",
    "    z = None\n",
    "    for zone in ZONES:\n",
    "        if zone in image_name:\n",
    "            z = zone\n",
    "            break\n",
    "    else:\n",
    "        sys.exit(\"unknown zone\")\n",
    "    if COUNTAIN_COFFEE in image_name:\n",
    "        images.append((np.array(rasterio.open(image_name).read()), 1, z))\n",
    "    else:\n",
    "        images.append((np.array(rasterio.open(image_name).read()), 0, z))\n",
    "print(\"Longueur initiale : \", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_all_rotations(images):\n",
    "    result = []\n",
    "    for image in images:\n",
    "        result.append(image)\n",
    "        for i in range (1, 4):\n",
    "            rotated_image = []\n",
    "            for j in range(12): #BAND_WIDTH\n",
    "                rotated_image.append(np.rot90(image[0][j], i))\n",
    "            result.append((rotated_image, image[1], image[2]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = add_all_rotations(images)\n",
    "random.shuffle(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for zone in ZONES:\n",
    "    data[zone] = {\"x\":[], \"y\":[]}\n",
    "for image in images:\n",
    "    data[image[2]][\"x\"].append(reshape(image[0]))\n",
    "    data[image[2]][\"y\"].append(image[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deuxième étape : créer notre cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics as me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=NB_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data:\n",
    "    data[key][\"x\"] = np.array(data[key][\"x\"])\n",
    "    data[key][\"y\"] = np.array(data[key][\"y\"])\n",
    "    print(np.count_nonzero(data[key][\"y\"] < 1), len(data[key][\"y\"]))\n",
    "    print(np.count_nonzero(data[key][\"y\"] < 1) / len(data[key][\"y\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Troisième étape : entrainer et tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fscore_recall_precision(truth, prediction):\n",
    "    true_positive = 0\n",
    "    false_negative = 0\n",
    "    false_positive = 0\n",
    "    for i in range(len(truth)):\n",
    "        if truth[i] == 1 and prediction[i] == 1:\n",
    "            true_positive += 1\n",
    "        elif truth[i] == 0 and prediction[i] == 1:\n",
    "            false_positive += 1\n",
    "        elif truth[i] == 1 and prediction[i] == 0:\n",
    "            false_negative += 1\n",
    "    precision = true_positive/(true_positive + false_positive) if (true_positive + false_positive) > 0 else None\n",
    "    recall = true_positive/(true_positive + false_negative) if (true_positive + false_negative) > 0 else None\n",
    "    fscore = 2 * recall * precision / (recall + precision) if recall != None and precision != None else None\n",
    "    return fscore, recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "\n",
    "i = 0\n",
    "for key in data:\n",
    "    # balance classes\n",
    "    class_weight = None\n",
    "    coffee = np.count_nonzero(data[key][\"y\"] == 1)\n",
    "    other = len(data[key][\"y\"]) - coffee\n",
    "    if other >= coffee:\n",
    "        class_weight = {0: 1.,1: other / coffee}  \n",
    "    else:\n",
    "        class_weight = {0: coffee / other,1: 1.} \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), activation='relu',  input_shape=(PIXEL_LENGTH,PIXEL_LENGTH,BAND_WIDTH)))\n",
    "    model.add(MaxPooling2D(pool_size = (2 ,2)))\n",
    "    model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2 ,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    history = model.fit(data[key][\"x\"], data[key][\"y\"], epochs=EPOCH, batch_size=32, class_weight=class_weight)\n",
    "\n",
    "    print(\"Trained on\", key)\n",
    "    avg_scores = []\n",
    "    avg_recall = []\n",
    "    avg_precision = []\n",
    "    avg_fscore = [] \n",
    "    model.save(\"model_\" + key + \".h5\")\n",
    "    for key2 in data:\n",
    "        if key2 != key:\n",
    "            # evaluate the model\n",
    "            print(\"Tested on\", key2)\n",
    "            scores = model.evaluate(data[key2][\"x\"], data[key2][\"y\"], verbose=0)\n",
    "            print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "            avg_scores.append(scores[1] * 100)\n",
    "\n",
    "\n",
    "            print('Test score:', scores[0])\n",
    "            print('Test accuracy:', scores[1])\n",
    "\n",
    "            pred = model.predict_classes(data[key2][\"x\"])\n",
    "            f, r, p = get_fscore_recall_precision(data[key2][\"y\"], pred)\n",
    "            print('Test recall', r)\n",
    "            print('Test precision', p)\n",
    "            print('Test f-score', f)\n",
    "            avg_recall.append(r * 100)\n",
    "            avg_precision.append(p * 100)\n",
    "            avg_fscore.append(f * 100)\n",
    "            print(me.confusion_matrix(data[key2][\"y\"], pred))\n",
    "\n",
    "    print(\"Visibility %.2f%% (+/- %.2f%%)\" % (np.mean(avg_scores), np.std(avg_scores)))\n",
    "    print(\"Recall %.2f%% (+/- %.2f%%)\" % (np.mean(avg_recall), np.std(avg_recall)))\n",
    "    print(\"Precision %.2f%% (+/- %.2f%%)\" % (np.mean(avg_precision), np.std(avg_precision)))\n",
    "    print(\"F-Score %.2f%% (+/- %.2f%%)\" % (np.mean(avg_fscore), np.std(avg_fscore)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
